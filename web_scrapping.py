# -*- coding: utf-8 -*-
"""Web scrapping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10NBMKppsPyJHBPAsVSyrGTTbZ2QpFUFX
"""

# Loading required libraries

import numpy as np
import pandas as pd

import requests
from bs4 import BeautifulSoup

# Identify the URL

URL = "https://timely-sunshine-e821b3.netlify.app/"

# Loading the WebPage in Memory using requests library

page = requests.get(URL)

# Check the Status Code of the Page
page.status_code

# Extracting the HTML Code of the WebPage
htmlCode = page.text
soup = BeautifulSoup(htmlCode)

htmlCode

content = soup.find('div', attrs={'class' : 'name'})
text = content.text
print(text)

content = soup.find('div', attrs={'class' : 'name'})
text = content.text.strip()
print(text)

content = soup.find('div', attrs={'class' : 'price'})
text = content.text
print(text)

content = soup.find('div', attrs={'class' : 'price'})
text = content.text.strip()
print(text)

content = soup.find('div', attrs={'class' : 'main'})

print(content.text)

content = soup.find('div', attrs={'class' : 'main'})
text=content.text
r1 = text.split("\n")
#print(r1)
r2 = []
for i in r1:
  if i != '' and i != '\r':
    r2.append(i)
#print(r2)
r3 = []
for i in r2:
  k = i.strip()
  r3.append(k)
#print(r3)
r4 = []
for i in r3:
  if i != '':
    r4.append(i)
#print(r4)
names = []
prices = []
for i in range(0,len(r4),2):
  names.append(r4[i])
  prices.append(r4[i+1])
print(names)
print(prices)

df = pd.DataFrame({'Product_Name' : names,'MRP' : prices})

df

df.shape

df.head()

df.to_csv('sample.csv', header=True, index=False)

from google.colab import files
files.download('sample.csv')